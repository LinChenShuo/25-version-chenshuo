# 1. CMake 框架搭建

## 1.1. 代码思路

（因为两个都是大差不差的东西所以干脆一起说了）

最顶层CMakeLists.txt输出要运行的可执行文件（为了学长说的module间有独立性减少耦合，我把test的可执行文件放在其归属的位置实现，但貌似不推荐？），并且执行中间层文件，添加编译选项

中间层CMakeLists.txt起一个跳板和规整的作用，指向最底层的CMakeLists.txt

最底层CMakeLists.txt输出需要的库给顶层输出的可执行文件链接

## 1.2. 遇到问题

解决思路在下面对应。

1. 刚开始的时候没有想明白链接，以为链库还要链相应的头文件
2. 有些时候会报缺少链接

## 1.3. 解决思路

1. “库”（或者说一个“模块”）本身就包含了源文件和库文件，概念搞反了
2. 有一定概率是输入的路径是空的问题，多message多输出学会“调试”

## 1.4. 效果图

- 任务一

![image-20241006193910785](/home/shuo/.config/Typora/typora-user-images/image-20241006193910785.png)

- 任务二

1. 测试

![image-20241006193114532](/home/shuo/.config/Typora/typora-user-images/image-20241006193114532.png)

![image-20241006193407236](/home/shuo/.config/Typora/typora-user-images/image-20241006193407236.png)

2. BUILD_A server

![image-20241006193524153](/home/shuo/.config/Typora/typora-user-images/image-20241006193524153.png)

3. BUILD_B server

![image-20241006193700498](/home/shuo/.config/Typora/typora-user-images/image-20241006193700498.png)

4. client

![image-20241006193609135](/home/shuo/.config/Typora/typora-user-images/image-20241006193609135.png)

## 1.5. 总结

我觉得本来混乱的思路，最后能够很快清晰有两个因素：

- 某天晚上和刘哥偶然见了一面聊了一下，分享了彼此遇到的问题，聊了一下什么都好了
- 看了崔宇分享的文档

由此可见和别人多交流和系统学习的重要性！

PS：我没有链接学长提示的库也能跑，有点奇怪，可能是我的环境问题？





# 2. 装甲板识别

## 2.1. 代码思路

原先的代码思路：

- hsv提取（红蓝灯条分开处理）

- 识别并筛除灯条（几何限制加上）

下面出现分歧：原先的做法：

- 识别某个灯条的匹配对象（如果有符合条件的多个，则选择最优个，通过灯条最小矩形角度差或灯条最小矩形中间距离，最小为最优对象）
- 如果两个灯条互相为匹配对象，则判断为灯条对并存储

后面发现这样的效果不高，因为限制太多，而且每个灯条只输出一个对象，在一些疑似对象多个的时候很容易把另一个也差不多的给筛掉，后面再筛装甲板，更是所剩无几；而且，因为分成太多步骤，导致函数间要利用上一步的数据不是很方便，创造了太多没啥用的结构体。

为此还所以改成了：

- 每个图片的所有灯条组成灯条对作为备选，筛除不符合的灯条对

后面的思路又趋向一致：

- 灯条对找出中心，八个点选出最优的四个，来作为装甲板的四个定点
- 筛除装甲板
- 为装甲板的四个点排序（姑且理解为第三象限开始逆时针一周），方便后面喂数据
- PnP求解，输出位姿

## 2.2. 遇到问题

解决思路在下面对应，代码在编写的时候思路倒是很清晰，但主要卡在一些比较离谱的地方

1. vscode的debug不成功
2. opencv抽风一直打开不了视频
3. if-else嵌套写错、for的第二个和第三个
4. out-of-range了几次
5. 调很多参数，调得越来越迷糊

## 2.3. 解决思路

1. 配launch文件就好啦（算是最有成就的一点！之前只会copy csdn的现成的，也学过不过忘得差不多了，这次是自己编写的诶）
2. 自己编译安装的时候没有把一些库链接上，还是最后下了自动安装的4.5.4的库
3. 太久没有写c相关的编程是这样的，多犯错就老实了
4. 学会用debug查哪里throw了exception，希望下次能把那个调用堆栈的内容完全看明白
5. 多putText，多cout；干脆改代码，把代码结构优化和减层，要调的参数就少了；每次加多一个条件，不要贪，我以为的和opencv以为的很大概率不是一个东西hhh

## 2.4. 效果图

结果的打印是：白色框出灯条，绿色框出装甲板，白字是距离和位姿（旋转向量表示）

![image-20241006164325521](/home/shuo/.config/Typora/typora-user-images/image-20241006164325521.png)

![image-20241006164214649](/home/shuo/.config/Typora/typora-user-images/image-20241006164214649.png)

选了两帧有红有蓝的，大概是这样



下面说做得不好的地方，给自己挑挑刺

1. **黄色的灯条没有滤干净，导致会识别出来**（已尽量修改）

![image-20241006164425471](/home/shuo/.config/Typora/typora-user-images/image-20241006164425471.png)

有试图滤过，但是因为红色灯条的中间也是黄的所以不小心就会把黄的滤没了，然后变成两个灯条

如果问为什么不开闭运算或者模糊来滤波：尝试过，小的灯条会受损严重，甚至会变成两个，对小装甲板识别的效果就很差了。

如果再问为什么不通过大小限制来滤掉：尝试过，但是其他的正确装甲板在识别的时候会一闪一闪的（想不明白为什么，明明前后两帧形状差不多但是会被滤掉，而且明明设置的area限制非常宽绰（甚至到10以下），我怀疑是里面算面积没算好）；而且对于一些小装甲板，其实也会被滤掉



但最后试了一下，反向调把h的阈值调高反而好了很多，但我感觉emmm可能如果放在实战效果也会一般（因为其他效果没有什么改变，所以就这份文档不再修改了）

2. **有出现重复识别的现象，而且很难剔除（基本上很难用几何因素去限制）**

![image-20241006164729254](/home/shuo/.config/Typora/typora-user-images/image-20241006164729254.png)

其实用原来的思路（每个灯条只有最多一个partner）是不会出现这种现象的，但是那个限制太死，对装甲板的检测有些失灵。

3. **这种乱七八糟的非正方形的东西很难过滤掉**

![image-20241006164941434](/home/shuo/.config/Typora/typora-user-images/image-20241006164941434.png)

有尝试过用这个不规则的四边形的面积比框它的矩形面积的比值来做过滤，但同样会滤掉有用的（哪怕把限定值设得很小）。

# 2.5 总结

坦白讲我对我这次完成的效果不满意，先来写这个代码的不足（除了上面的不足）：

- 筛选条件太少，我感觉可以再加，但不知道为什么每次想要再加都会把好的也筛掉，坏的倒没筛走
- 写得不够干净，我觉得可以少创建一些变量，让计算机少跑一些有的没的，下次希望多多注意！

但再拘泥于此我感觉学不到什么东西了。我已经尽全力做到我能做到的最佳效果了，那么也就没有什么对不住自己的事情了。

在做这个任务的时候我想了几个问题：

1. **做成数据集，换成神经网络进去跑**，是不是能效果好很多？（因为在原视频里会有装甲板数字的信息，而且把整个图像调暗灯条的形状也变形，对于小灯条来说损失很大，何况后面还要将图像过滤噪点，损失更严重。）

   当然我相信到时候赛博炼丹也有赛博炼丹的难处（笑）。

2. 这份作业我在完成的时候除了开头查了两篇csdn，看了一下开源的基本思路（没有看代码，一个原因是当时还看不懂opencv的相关代码），后面基本上都是自己写的代码，可以说独立完成的，但是后果是效果不怎么好，但还是不大愿意去看别人的思路（因为这不是在做项目只是在做作业），所以：这个实习期间的评价会以什么标准呢？会更倾向于**完成的效果**还是个人**独立完成的能力**呢？

   如果我自我选择的话，在学习阶段我还是更倾向于后者。但如果到项目阶段，不选前者就是高看自己闭门造车了。

3. 在完成的过程中我花了很多时间在调参，某种程度说明算法并不够优秀，接下来的项目还是**希望花少时间在对个人提升没有帮助的调参上**。

4. **对c++语法不熟悉**吃了很多的亏，比如我的if-else嵌套因为偷懒没有写括号就因此匹配错了很多次，格式化文档之后一直对错位我还想着为什么呢，结果往错误的方向调了不久时间。**对opencv一些类的内容也不够熟悉**，甚至理解错误（比如那个旋转矩形类的宽高和角度），也因此花了很多时间，不过这次把opencv熟悉了不少，也逐渐习惯了c++语法，再也不会for i in range了（bushi）！



还有一点代码的小问题，就是把灯条对的检测和装甲板的检测分开了qwq，这样其实相当于：根据矩形对筛一次（但没有具体筛选矩形位置关系），根据装甲板的矩形再筛选一次（但没有根据灯条的大小和装甲板的比例来筛选），也就是说，其实合在一起能筛选的效率应该（从人的视角来看）更高才对，但这样相当于把整个检测函数都揉在一起了，效率提高但结构就勉勉强强吧（自我反思ing）。